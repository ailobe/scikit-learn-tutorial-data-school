{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of model evaluation\n",
    "\n",
    "- Need a way to choose between models: different model types, tuning parameters, and features\n",
    "- Use a **model evaluation procedure** to estimate how well a model will generalize to out-of-sample data\n",
    "- Requires a **model evaluation metric** to quantify the model performance\n",
    "\n",
    "### Model evaluation procedures\n",
    "\n",
    "- **Train/test split**\n",
    "    - Split the dataset into two pieces, so that the model can be trained and tested on different data\n",
    "    - Better estimate of out-of-sample performance, but still a \"high variance\" estimate\n",
    "    - Useful due to its speed, simplicity, and flexibility\n",
    "- **K-fold cross-validation**\n",
    "    - Systematically create \"K\" train/test splits and average the results together\n",
    "    - Even better estimate of out-of-sample performance\n",
    "    - Runs \"K\" times slower than train/test split\n",
    "    \n",
    "### Model evaluation metrics\n",
    "\n",
    "- **Regression problems:**\n",
    "    - Mean Absolute Error\n",
    "    - Mean Squared Error\n",
    "    - Root Mean Squared Error\n",
    "- **Classification problems:**\n",
    "    - Classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification accuracy is not enough\n",
    "When you build a model for a classification problem the number of correct predictions from all predictions made is known as the classification accuracy. This metric alone it is alone is typically **not enough information to decide** whether or not your trained model is a good enough model to solve your problem. [Source](https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/)\n",
    "\n",
    "Imagine we are trying to classify tumors as benign or malignants. Of the 100 tumor examples, 90 are benign and 10 are malignant. While 90% accuracy may seem good at first glance, it could mean that the model correctly identifies 90 tumors as benign but misses all the malignants. Although 90/100 correct predictions is a nice number, 10 out of 10 malignancies go undiagnosed, so our not so long ago good model **in reality is a bad model**. [Source](https://developers.google.com/machine-learning/crash-course/classification/accuracy)\n",
    "\n",
    "Classification accuracy can **hide the detail you need to diagnose the performance** of your model. But thankfully we can tease apart this detail by using a confusion matrix. [Source](https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "- A confusion matrix is a **summary of prediction results** on a classification problem.\n",
    "- The number of correct and incorrect predictions are summarized with count values and broken down by each class in a **table with 4 different combinations of predicted and actual values**.\n",
    "- It gives you insight not only into the errors being made by your classifier but more importantly the **types of errors that are being made**. [Source](https://machinelearningmastery.com/confusion-matrix-machine-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Small confusion matrix](https://cdn-images-1.medium.com/max/800/1*Z54JgbS4DUwWSknhDCvNTQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic terminology**\n",
    "\n",
    "- **True Positive (TP):**\n",
    "    - Interpretation: You predicted **positive** and it’s **true**.\n",
    "    - Example: You predicted that a woman **is** pregnant and she actually **is**.\n",
    "- **True Negative (TN):**\n",
    "    - Interpretation: You predicted **negative** and it’s **true**.\n",
    "    - You predicted that a man **is not** pregnant and he actually **is not**.\n",
    "- **False Positive (FP):**\n",
    "    - Interpretation: You predicted **positive** and it’s **false** (a \"Type 1 Error\").\n",
    "    - You predicted that a man **is** pregnant but he actually **is not**.\n",
    "- **False Negative (FN):** \n",
    "    - Interpretation: You predicted **negative** and it’s **false** (a \"Type 2 Error\").\n",
    "    - You predicted that a woman **is not** pregnant but she actually **is**. \n",
    "[Source](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix example\n",
    "Let's predict the diabetes status of a patient given their health measurements using the [Pima Indians Diabetes dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database), originally from the UCI Machine Learning Repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# set the path\n",
    "path = 'data/pima-indians-diabetes.data'\n",
    "\n",
    "# create a list for the column names\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "\n",
    "# read the data into a pandas DataFrame\n",
    "pima = pd.read_csv(path, header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  bp  skin  insulin   bmi  pedigree  age  label\n",
       "0         6      148  72    35        0  33.6     0.627   50      1\n",
       "1         1       85  66    29        0  26.6     0.351   31      0\n",
       "2         8      183  64     0        0  23.3     0.672   32      1\n",
       "3         1       89  66    23       94  28.1     0.167   21      0\n",
       "4         0      137  40    35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 rows of data\n",
    "pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "\n",
    "# create a Python list of feature names\n",
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age']\n",
    "\n",
    "# use the list to select a subset of the original DataFrame\n",
    "X = pima[feature_cols]\n",
    "\n",
    "# select a Series from the DataFrame\n",
    "y = pima.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model on the training set\n",
    "\n",
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model to the training data\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for the testing set\n",
    "y_pred_class = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification accuracy:** percentage of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6927083333333334"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import metrics module\n",
    "from sklearn import metrics\n",
    "\n",
    "# calculate accuracy\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix:** table that describes the performance of a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 47  15]]\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted values\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Break down**\n",
    "- **TP: 118**\n",
    "    - Predicted that a person **has** diabetes and she actually **has**.\n",
    "- **TN: 15**\n",
    "    - Predicted that a person **hasn't** diabetes and she actually **hasn't**.\n",
    "- **FP: 12**\n",
    "    - Predicted that a person **has** diabetes and she actually **hasn't**.\n",
    "- **FN: 47** \n",
    "    - Predicted that a person **hasn't** diabetes and she actually **has**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics computed from a confusion matrix\n",
    "A confusion matrix is extremely useful for measuring the following metrics: **Accuracy**, **Precision**, **Recall**, **Specificity**, and most importantly **AUC-ROC Curve**. [Source](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Accuracy:** What fraction of predictions got right our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6927083333333334"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision:** What proportion of positive identifications was actually correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall** (also called **true positive rate**): What proportion of actual positives was identified correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24193548387096775"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity** (also called **true negative rate**): What proportion of actual positives was identified correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **ROC curve** (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. \n",
    "- ROC curves typically feature True Positive Rate **(TPR) on the Y axis**, and False Positive Rate **(FPR) on the X axis**. This means that the top left corner of the plot is the “ideal” point - a false positive rate of zero, and a true positive rate of one.\n",
    "- The “steepness” of ROC curves is also important, since it is ideal to maximize the true positive rate while minimizing the false positive rate.\n",
    "\n",
    "Lowering the classification threshold classifies more items as positive, thus increasing both False Positives and True Positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63247571, 0.36752429],\n",
       "       [0.71643656, 0.28356344],\n",
       "       [0.71104114, 0.28895886],\n",
       "       [0.5858938 , 0.4141062 ],\n",
       "       [0.84103973, 0.15896027],\n",
       "       [0.82934844, 0.17065156],\n",
       "       [0.50110974, 0.49889026],\n",
       "       [0.48658459, 0.51341541],\n",
       "       [0.72321388, 0.27678612],\n",
       "       [0.32810562, 0.67189438]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROC curve uses the estimates of the positive class to plot the True Positive Rate and True Negative Rate\n",
    "\n",
    "# return estimates for all classes ordered by label: ['index 0 is negative', 'index 1 is positive'].\n",
    "logreg.predict_proba(X_test)[:5,:] # [5 rows, all columns]\n",
    "\n",
    "# by default predicts True if estimate >= 0.5 (treshhold == 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the probability estimates of the positive class\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1] # [all rows, index 1 column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# allow plots to appear in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# store the three arrays that are returned when ROC curve is computed: FPR, TPR and treshholds\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob) # args: (true values, predicted probabilities)\n",
    "\n",
    "# plot FPR TPR\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for diabetes classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Area Under the Curve (AUC)** is the percentage of the ROC plot that is underneath the curve. It's THE metric we consider of this curve: a larger AUC is usually better.\n",
    "- AUC is useful as a **single number summary** of classifier performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5748138957816378"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7378233618233618"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cross validation function\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# calculate cross-validated AUC\n",
    "cross_val_score(logreg, X, y, cv=10, scoring='roc_auc').mean() # scoring='roc_auc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to map a probability estimate to a binary category, you must define a **classification threshold**. A value above that threshold indicates \"True\"; a value below indicates \"False\". It is tempting to assume that the classification threshold should always be 0.5, but thresholds are **problem-dependent**, and are therefore values that you must tune.\n",
    "\n",
    "We can use the metrics we have seen so far to evaluate a classification model's predictions, as well as the impact of changing the classification threshold on these predictions.\n",
    "\n",
    "Part of choosing a threshold is assessing **how much you'll suffer for making a mistake**. For example, mistakenly labeling a non-spam message as spam is very bad. However, mistakenly labeling a spam message as non-spam is unpleasant, but hardly the end of your job. [Source](https://developers.google.com/machine-learning/crash-course/classification/thresholding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECREASE THE TRESHOLD\n",
    "\n",
    "# storing previous confusion matrix for comparison\n",
    "old_confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "# importing tresholding function\n",
    "from sklearn.preprocessing import binarize\n",
    "\n",
    "# predict diabetes if the predicted probability is greater than 0.3\n",
    "y_pred_class = binarize([y_pred_prob], 0.3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[80, 50],\n",
       "       [16, 46]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previous confusion matrix (default threshold of 0.5)\n",
    "old_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[80 50]\n",
      " [16 46]]\n"
     ]
    }
   ],
   "source": [
    "# new confusion matrix (threshold of 0.3)\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Break down**\n",
    "- **TP: 80**\n",
    "    - Predicted that a person **has** diabetes and she actually **has**.\n",
    "- **TN: 46**\n",
    "    - Predicted that a person **hasn't** diabetes and she actually **hasn't**.\n",
    "- **FP: 50**\n",
    "    - Predicted that a person **has** diabetes and she actually **hasn't**.\n",
    "- **FN: 16** \n",
    "    - Predicted that a person **hasn't** diabetes and she actually **has**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65625"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification Accuracy: What fraction of predictions got right our model?\n",
    "# old accuracy: 0.6927083333333334\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4791666666666667"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision: What proportion of positive identifications was actually correct?\n",
    "# old precision: 0.5555555555555556\n",
    "metrics.precision_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7419354838709677"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall (true positive rate): What proportion of actual positives was identified correctly?\n",
    "# old recall: 0.24193548387096775\n",
    "metrics.recall_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specificity (also called true negative rate): What proportion of actual positives was identified correctly?\n",
    "# old:\n",
    "metrics.f1_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6786600496277917"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old AUC: 0.5748138957816378\n",
    "metrics.roc_auc_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
